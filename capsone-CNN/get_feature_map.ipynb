{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet50,resnet18\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from collections import OrderedDict\n",
    "import torchsummary\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation():\n",
    "    def __init__(self,module):\n",
    "        self.hook = module.register_forward_hook(self.hook_fn)\n",
    "\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.features = output.detach()\n",
    "\n",
    "    def remove(self):\n",
    "        self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_list(model):\n",
    "    list = OrderedDict()\n",
    "    for name,layer in model.named_modules():\n",
    "        if name == '':\n",
    "            continue\n",
    "        list[name] = layer\n",
    "    return list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = resnet18()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "        #activation[name] = output.data.numpy()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,module in model.named_modules():\n",
    "    if isinstance(module,nn.Conv2d):\n",
    "        module.register_forward_hook(get_activation(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "activation = {}\n",
    "activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = model(torch.randn(3,224,224).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torchsummary.summary(model,(3,224,224), device = 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from models.resnet import resnet18\n",
    "\n",
    "use_layer = ['layer1.1.conv1', 'layer1.1.conv2', 'layer2.0.conv1', 'layer2.0.conv2', 'layer2.1.conv2', 'layer3.0.conv1',\n",
    "            'layer3.0.conv2', 'layer4.0.conv1', 'layer4.1.conv1', 'layer4.1.conv2']\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "        #activation[name] = output.data.numpy()\n",
    "    return hook\n",
    "\n",
    "save_path = r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\test\\actMap'\n",
    "image_path = r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\test\\images'\n",
    "state_path = r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\results\\experiment\\baseline\\99_net_sign.pth'\n",
    "# ResNet-18 모델을 불러옵니다.\n",
    "model = resnet18()\n",
    "#model = torch.nn.Sequential(*list(model.children())[:-3])\n",
    "model.load_state_dict(torch.load(state_path))\n",
    "loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27-양화로 상3 근_002.jpg\n",
      "마포대교 신규등록3-general-0_004.jpg\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for name,module in model.named_modules():\n",
    "    #print(module)\n",
    "    if isinstance(module,nn.Conv2d):\n",
    "        module.register_forward_hook(get_activation(name))\n",
    "\n",
    "\n",
    "# 이미지 변환을 위한 전처리 함수를 정의합니다.\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "for img in os.listdir(image_path):\n",
    "    print(img)\n",
    "    # 이미지를 불러옵니다.\n",
    "    image = Image.open(os.path.join(image_path,img)).convert(\"RGB\")\n",
    "    dir_path = os.path.join(save_path,img)\n",
    "    \n",
    "    if os.path.isdir(dir_path) == False:\n",
    "        os.mkdir(dir_path)\n",
    "    # 이미지를 전처리합니다.\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "    x = input_batch\n",
    "    # 이미지를 모델에 통과시켜 activation map을 얻습니다.\n",
    "    \n",
    "    activation = {}\n",
    "    output = model(x)\n",
    "    \n",
    "    # 각 레이어의 activation map을 파일로 저장합니다.\n",
    "    for idx, activation_map in enumerate(activation.items()):\n",
    "        path = os.path.join(save_path,img)\n",
    "        file_name = f'{img}_{activation_map[0]}'\n",
    "        to_np = activation_map[1].numpy()\n",
    "        np.save(os.path.join(path,file_name),activation_map[1])\n",
    "        #print(f\"Activation map for Layer {idx+1}({activation_map[0]}): {activation_map[1].shape} saved\")\n",
    "        #activation_map = activation_map.squeeze(dim=0)\n",
    "    #print(f\"{img}'s npy file saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['27-양화로 상3 근_002.jpg', '마포대교 신규등록3-general-0_004.jpg']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_path = r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\test\\actMap'\n",
    "npList = os.listdir(np_path)\n",
    "npList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\n",
      "layer1.0.conv1\n",
      "layer1.0.conv2\n",
      "layer1.1.conv1\n",
      "layer1.1.conv2\n",
      "layer2.0.conv1\n",
      "layer2.0.conv2\n",
      "layer2.0.downsample.0\n",
      "layer2.1.conv1\n",
      "layer2.1.conv2\n",
      "layer3.0.conv1\n",
      "layer3.0.conv2\n",
      "layer3.0.downsample.0\n",
      "layer3.1.conv1\n",
      "layer3.1.conv2\n",
      "layer4.0.conv1\n",
      "layer4.0.conv2\n",
      "layer4.0.downsample.0\n",
      "layer4.1.conv1\n",
      "layer4.1.conv2\n"
     ]
    }
   ],
   "source": [
    "for i in activation.items():\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마포대교 신규등록3-general-0_004.jpg and 용산효창원길0013(근)-general-0_004.jpg's conv1 loss : 0.27670812606811523\n",
      "마포대교 신규등록3-general-0_004.jpg and 용산효창원길0013(근)-general-0_004.jpg's layer1.0.conv1 loss : 6.959519863128662\n",
      "마포대교 신규등록3-general-0_004.jpg and 용산효창원길0013(근)-general-0_004.jpg's layer1.0.conv2 loss : 8.227204322814941\n",
      "마포대교 신규등록3-general-0_004.jpg and 용산효창원길0013(근)-general-0_004.jpg's layer1.1.conv1 loss : 23.035491943359375\n",
      "마포대교 신규등록3-general-0_004.jpg and 용산효창원길0013(근)-general-0_004.jpg's layer1.1.conv2 loss : 23.595420837402344\n",
      "마포대교 신규등록3-general-0_004.jpg and 용산효창원길0013(근)-general-0_004.jpg's layer2.0.conv1 loss : 35.7568244934082\n",
      "마포대교 신규등록3-general-0_004.jpg and 용산효창원길0013(근)-general-0_004.jpg's layer2.0.conv2 loss : 42.86428451538086\n",
      "마포대교 신규등록3-general-0_004.jpg and 용산효창원길0013(근)-general-0_004.jpg's layer2.0.downsample.0 loss : 2.043657064437866\n",
      "마포대교 신규등록3-general-0_004.jpg and 용산효창원길0013(근)-general-0_004.jpg's layer2.1.conv1 loss : 58.09381866455078\n",
      "마포대교 신규등록3-general-0_004.jpg and 용산효창원길0013(근)-general-0_004.jpg's layer2.1.conv2 loss : 41.0594367980957\n",
      "마포대교 신규등록3-general-0_004.jpg and 용산효창원길0013(근)-general-0_004.jpg's layer3.0.conv1 loss : 97.53404235839844\n",
      "마포대교 신규등록3-general-0_004.jpg and 용산효창원길0013(근)-general-0_004.jpg's layer3.0.conv2 loss : 73.39813995361328\n",
      "마포대교 신규등록3-general-0_004.jpg and 용산효창원길0013(근)-general-0_004.jpg's layer3.0.downsample.0 loss : 5.625256538391113\n",
      "마포대교 신규등록3-general-0_004.jpg and 용산효창원길0013(근)-general-0_004.jpg's layer3.1.conv1 loss : 73.3635482788086\n",
      "마포대교 신규등록3-general-0_004.jpg and 용산효창원길0013(근)-general-0_004.jpg's layer3.1.conv2 loss : 34.61906051635742\n",
      "마포대교 신규등록3-general-0_004.jpg and 용산효창원길0013(근)-general-0_004.jpg's layer4.0.conv1 loss : 53.39431381225586\n",
      "마포대교 신규등록3-general-0_004.jpg and 용산효창원길0013(근)-general-0_004.jpg's layer4.0.conv2 loss : 16.44422721862793\n",
      "마포대교 신규등록3-general-0_004.jpg and 용산효창원길0013(근)-general-0_004.jpg's layer4.0.downsample.0 loss : 2.375858783721924\n",
      "마포대교 신규등록3-general-0_004.jpg and 용산효창원길0013(근)-general-0_004.jpg's layer4.1.conv1 loss : 235.3056640625\n",
      "마포대교 신규등록3-general-0_004.jpg and 용산효창원길0013(근)-general-0_004.jpg's layer4.1.conv2 loss : 17.370132446289062\n",
      "마포대교 신규등록3-general-0_004.jpg and 용산효창원길0013(근)-general-0_004.jpg's loss sum : 0\n"
     ]
    }
   ],
   "source": [
    "#같은 class\n",
    "for ori in npList:\n",
    "    mse = 0\n",
    "    map1 = os.path.join(np_path,ori)\n",
    "    for comp in npList:\n",
    "        mse = 0\n",
    "        #min_loss = sys.maxsize\n",
    "        #min_loss_conv = ''\n",
    "        map2 = os.path.join(np_path,comp)\n",
    "        if ori == comp:\n",
    "            continue\n",
    "        for activation_map in activation.items():\n",
    "            n1 = torch.from_numpy(np.load(os.path.join(map1,ori) + f'_{activation_map[0]}.npy'))\n",
    "            n2 = torch.from_numpy(np.load(os.path.join(map2,comp) + f'_{activation_map[0]}.npy'))\n",
    "            #result = np.mean((n1-n2)**2)\n",
    "            result = loss(n1,n2)\n",
    "            #mse += result\n",
    "            print(f\"{ori} and {comp}'s {activation_map[0]} loss : {result}\")\n",
    "        print(f\"{ori} and {comp}'s loss sum : {mse}\")\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27-양화로 상3 근_002.jpg and 마포대교 신규등록3-general-0_004.jpg's conv1 loss : 0.9034370183944702\n",
      "27-양화로 상3 근_002.jpg and 마포대교 신규등록3-general-0_004.jpg's layer1.0.conv1 loss : 20.517311096191406\n",
      "27-양화로 상3 근_002.jpg and 마포대교 신규등록3-general-0_004.jpg's layer1.0.conv2 loss : 20.578065872192383\n",
      "27-양화로 상3 근_002.jpg and 마포대교 신규등록3-general-0_004.jpg's layer1.1.conv1 loss : 48.40366744995117\n",
      "27-양화로 상3 근_002.jpg and 마포대교 신규등록3-general-0_004.jpg's layer1.1.conv2 loss : 42.94108200073242\n",
      "27-양화로 상3 근_002.jpg and 마포대교 신규등록3-general-0_004.jpg's layer2.0.conv1 loss : 60.58995819091797\n",
      "27-양화로 상3 근_002.jpg and 마포대교 신규등록3-general-0_004.jpg's layer2.0.conv2 loss : 79.87269592285156\n",
      "27-양화로 상3 근_002.jpg and 마포대교 신규등록3-general-0_004.jpg's layer2.0.downsample.0 loss : 3.653759479522705\n",
      "27-양화로 상3 근_002.jpg and 마포대교 신규등록3-general-0_004.jpg's layer2.1.conv1 loss : 79.75484466552734\n",
      "27-양화로 상3 근_002.jpg and 마포대교 신규등록3-general-0_004.jpg's layer2.1.conv2 loss : 51.03647232055664\n",
      "27-양화로 상3 근_002.jpg and 마포대교 신규등록3-general-0_004.jpg's layer3.0.conv1 loss : 117.4683837890625\n",
      "27-양화로 상3 근_002.jpg and 마포대교 신규등록3-general-0_004.jpg's layer3.0.conv2 loss : 75.86011505126953\n",
      "27-양화로 상3 근_002.jpg and 마포대교 신규등록3-general-0_004.jpg's layer3.0.downsample.0 loss : 7.103745937347412\n",
      "27-양화로 상3 근_002.jpg and 마포대교 신규등록3-general-0_004.jpg's layer3.1.conv1 loss : 81.9441146850586\n",
      "27-양화로 상3 근_002.jpg and 마포대교 신규등록3-general-0_004.jpg's layer3.1.conv2 loss : 41.1303596496582\n",
      "27-양화로 상3 근_002.jpg and 마포대교 신규등록3-general-0_004.jpg's layer4.0.conv1 loss : 61.37316131591797\n",
      "27-양화로 상3 근_002.jpg and 마포대교 신규등록3-general-0_004.jpg's layer4.0.conv2 loss : 20.824203491210938\n",
      "27-양화로 상3 근_002.jpg and 마포대교 신규등록3-general-0_004.jpg's layer4.0.downsample.0 loss : 2.667799949645996\n",
      "27-양화로 상3 근_002.jpg and 마포대교 신규등록3-general-0_004.jpg's layer4.1.conv1 loss : 362.4007568359375\n",
      "27-양화로 상3 근_002.jpg and 마포대교 신규등록3-general-0_004.jpg's layer4.1.conv2 loss : 23.01836585998535\n",
      "27-양화로 상3 근_002.jpg and 마포대교 신규등록3-general-0_004.jpg's loss sum : 1202.042236328125\n"
     ]
    }
   ],
   "source": [
    "#다른 class\n",
    "for ori in npList:\n",
    "    mse = 0\n",
    "    map1 = os.path.join(np_path,ori)\n",
    "    for comp in npList:\n",
    "        mse = 0\n",
    "        #min_loss = sys.maxsize\n",
    "        #min_loss_conv = ''\n",
    "        map2 = os.path.join(np_path,comp)\n",
    "        if ori == comp:\n",
    "            continue\n",
    "        for activation_map in activation.items():\n",
    "            n1 = torch.from_numpy(np.load(os.path.join(map1,ori) + f'_{activation_map[0]}.npy'))\n",
    "            n2 = torch.from_numpy(np.load(os.path.join(map2,comp) + f'_{activation_map[0]}.npy'))\n",
    "            #result = np.mean((n1-n2)**2)\n",
    "            result = loss(n1,n2)\n",
    "            mse += result\n",
    "            print(f\"{ori} and {comp}'s {activation_map[0]} loss : {result}\")\n",
    "        print(f\"{ori} and {comp}'s loss sum : {mse}\")\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from models.resnet import resnet18\n",
    "\n",
    "use_layer = ['layer1.1.conv1', 'layer1.1.conv2', 'layer2.0.conv1', 'layer2.0.conv2', 'layer2.1.conv2', 'layer3.0.conv1',\n",
    "            'layer3.0.conv2', 'layer4.0.conv1', 'layer4.1.conv1', 'layer4.1.conv2']\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "        #activation[name] = output.data.numpy()\n",
    "    return hook\n",
    "\n",
    "loss_criterion = nn.MSELoss()\n",
    "save_path = r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\test\\actMap'\n",
    "image_path = r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\test\\images'\n",
    "state_path = r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\results\\experiment\\baseline\\99_net_sign.pth'\n",
    "# ResNet-18 모델을 불러옵니다.\n",
    "model = resnet18()\n",
    "#model = torch.nn.Sequential(*list(model.children())[:-3])\n",
    "model.load_state_dict(torch.load(state_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation shape: torch.Size([2, 569])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for name,module in model.named_modules():\n",
    "    #print(module)\n",
    "    #if isinstance(module,nn.Conv2d):\n",
    "    if name in use_layer:\n",
    "        module.register_forward_hook(get_activation(name))\n",
    "# 이미지를 불러오고 전처리하는 변환 함수\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "activation = {}\n",
    "# 이미지들을 묶어서 처리할 배치 텐서 생성\n",
    "batch = []\n",
    "for img in os.listdir(image_path):\n",
    "    image = Image.open(os.path.join(image_path,img)).convert(\"RGB\")\n",
    "    input_tensor = preprocess(image)\n",
    "    batch.append(input_tensor)\n",
    "\n",
    "# 배치 텐서 생성\n",
    "batch_tensor = torch.stack(batch, dim=0)\n",
    "\n",
    "# 배치 텐서를 모델에 전달하여 activation 얻기\n",
    "with torch.no_grad():\n",
    "    output = model(batch_tensor)\n",
    "\n",
    "print(\"Activation shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.1.conv1\n",
      "layer1.1.conv2\n",
      "layer2.0.conv1\n",
      "layer2.0.conv2\n",
      "layer2.1.conv2\n",
      "layer3.0.conv1\n",
      "layer3.0.conv2\n",
      "layer4.0.conv1\n",
      "layer4.1.conv1\n",
      "layer4.1.conv2\n"
     ]
    }
   ],
   "source": [
    "for a in activation.items():\n",
    "    print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in activation.items():\n",
    "    #print(a[1][0].shape)\n",
    "    #temp = a[1][0].unsqueeze(0)\n",
    "    #print(temp.shape)\n",
    "    #print(a[1].shape)\n",
    "    print(a[1][0].unsqueeze(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for name,module in model.named_modules():\n",
    "    #print(module)\n",
    "    if isinstance(module,nn.Conv2d):\n",
    "        module.register_forward_hook(get_activation(name))\n",
    "\n",
    "\n",
    "# 이미지 변환을 위한 전처리 함수를 정의합니다.\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "for img in os.listdir(image_path):\n",
    "    # 이미지를 불러옵니다.\n",
    "    #image = Image.open(r'D:\\ms\\capstone\\dataset\\custom\\comb\\test_for_actMap\\general2.jpg').convert(\"RGB\")\n",
    "    image = Image.open(os.path.join(image_path,img)).convert(\"RGB\")\n",
    "    print(image)\n",
    "    # 이미지를 전처리합니다.\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "    x = input_batch\n",
    "    # 이미지를 모델에 통과시켜 activation map을 얻습니다.\n",
    "    \n",
    "    activation = {}\n",
    "    output = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "activation['conv1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "activation['conv1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.load(r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\activationMap\\0\\0_conv1.npy').shape)\n",
    "print(np.load(r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\activationMap\\0\\0_layer1.0.conv1.npy').shape)\n",
    "print(np.load(r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\activationMap\\0\\0_layer2.1.conv2.npy').shape)\n",
    "print(np.load(r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\activationMap\\0\\0_layer4.1.conv1.npy').shape)\n",
    "print(np.load(r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\activationMap\\0\\0_layer4.1.conv2.npy').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_iter(activation):\n",
    "    for a in activation:\n",
    "        yield a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb_act(activation):\n",
    "    yield from act_iter(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(torch.from_numpy(np.load(r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\activationMap\\1\\1_conv1.npy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_feature(activation,label):\n",
    "    path = os.path.join(act_path,label)\n",
    "    for a in activation.items():\n",
    "        file_name = os.path.join(path,f'{label}_{a[0]}.npy')\n",
    "        print(file_name)\n",
    "        sub_param = nn.Parameter(torch.from_numpy(np.load(file_name)))\n",
    "        optimizer = optim.Adam([sub_param],lr=0.01)\n",
    "        loss = loss_criterion(sub_param,a[1])\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(type(sub_param.data))\n",
    "        #np.save(file_name,sub_param.data.numpy())\n",
    "        #print(sub_param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_feature(activation,str(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimize_feature(activation,str(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_path = r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\test_map\\1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in os.listdir(t_path):\n",
    "    #print(d)\n",
    "    print(np.load(os.path.join(t_path,d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in os.listdir(t_path):\n",
    "    #print(d)\n",
    "    print(np.load(os.path.join(t_path,d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2 = torch.from_numpy(np.load(r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\test_map\\0\\0_conv1.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sub_param = nn.Parameter(n2)\n",
    "#sub_param = nn.Parameter(torch.Tensor(n2))\n",
    "#optimizer = optim.SGD([sub_param], lr=0.1)\n",
    "optimizer = optim.Adam([sub_param],lr=0.01)\n",
    "loss_criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(5):\n",
    "    optimizer.zero_grad() \n",
    "    \n",
    "    #loss.requires_grad_(True)\n",
    "    loss = loss_criterion(sub_param,n1)\n",
    "    print(loss)\n",
    "    \n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()  \n",
    "    \n",
    "    #print(sub_param.data)\n",
    "    #print(\"n2:\")\n",
    "    #print(n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 행렬 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = []\n",
    "for i in activation.items():\n",
    "    arrays.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shapes start')\n",
    "shapes = [n.shape for n in arrays] \n",
    "print('shapes done')\n",
    "\n",
    "print('final start')\n",
    "final = np.vstack(shapes).max(axis=0)\n",
    "print('final done')\n",
    "\n",
    "print('out start')\n",
    "\n",
    "out = np.concatenate([np.pad(a, list(zip_longest([0], final-a.shape,\n",
    "                                                 fillvalue=0)), 'constant')\n",
    "                      for a in arrays])\n",
    "print('out done')\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_np = np.load(r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\activationMap\\0_activation.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(out))\n",
    "print(type(sub_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.Tensor(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_np = torch.from_numpy(np.load(r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\activationMap\\0_activation.npy'))\n",
    "print(out.requires_grad)\n",
    "print(sub_np.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_np.requires_grad_(True)\n",
    "out.requires_grad_(True)\n",
    "print(out.requires_grad)\n",
    "print(sub_np.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_param = nn.Parameter(sub_np,requires_grad=True)\n",
    "optimizer = optim.SGD([sub_param], lr=0.01)\n",
    "\n",
    "for epoch in range(5):\n",
    "    optimizer.zero_grad()  # 그래디언트 초기화\n",
    "\n",
    "    loss = loss_criterion(out,sub_param)\n",
    "    print(loss)\n",
    "    #loss.requires_grad_(True)\n",
    "    # 역전파 및 업데이트\n",
    "    loss.backward()\n",
    "    optimizer.step()  # 활성화 맵 업데이트\n",
    "\n",
    "    print(f\"{epoch} : Updated input activation map:\")\n",
    "    #print(sub_param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시로 사용할 텐서를 생성합니다.\n",
    "sub_np = torch.randn((1, 10), requires_grad=True)  # 예시로 1x10 텐서 생성\n",
    "print(type(sub_np))\n",
    "print(sub_np.requires_grad)\n",
    "# 텐서를 다른 파라미터로 감싸고 최적화합니다.\n",
    "sub_param = nn.Parameter(sub_np)\n",
    "optimizer = optim.SGD([sub_param], lr=0.1)\n",
    "\n",
    "# 최적화를 위해 몇 번의 반복을 수행합니다.\n",
    "for epoch in range(5):\n",
    "    optimizer.zero_grad()  # 그래디언트 초기화\n",
    "\n",
    "    # 손실 계산\n",
    "    loss = torch.sum(sub_param ** 2)  # 예시로 간단한 손실 계산\n",
    "    print(loss)\n",
    "\n",
    "    # 역전파 및 업데이트\n",
    "    loss.backward()\n",
    "    optimizer.step()  # 파라미터 업데이트\n",
    "\n",
    "    # 업데이트된 값을 출력합니다.\n",
    "    print(\"Updated parameter value:\")\n",
    "    print(sub_param.data)  # 업데이트된 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 예시로 사용할 텐서를 생성합니다.\n",
    "sub_np = torch.from_numpy(np.load(r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\test_map\\0\\0_conv1.npy'))\n",
    "\n",
    "# 텐서를 다른 파라미터로 감싸고 최적화합니다.\n",
    "sub_param = nn.Parameter(sub_np)\n",
    "optimizer = optim.Adam([sub_param], lr=0.1)\n",
    "\n",
    "# 손실 함수 객체 생성\n",
    "loss_criterion = nn.MSELoss()\n",
    "\n",
    "# 최적화를 위해 몇 번의 반복을 수행합니다.\n",
    "for epoch in range(5):\n",
    "    optimizer.zero_grad()  # 그래디언트 초기화\n",
    "\n",
    "    # 손실 계산\n",
    "    loss = loss_criterion(n1, sub_param)  # MSE 손실 계산\n",
    "\n",
    "    # 역전파 및 업데이트\n",
    "    loss.backward()\n",
    "    optimizer.step()  # 파라미터 업데이트\n",
    "\n",
    "    # 업데이트된 값을 출력합니다.\n",
    "    print(\"Updated parameter value:\")\n",
    "    print(sub_param.data)  # 업데이트된 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\test_map\\0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in os.listdir(path):\n",
    "    print(c)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = torch.from_numpy(np.load(r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\test_map\\0\\0_conv1.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = torch.flatten(n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = np.load(r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\test_map\\0\\0_conv1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in activation.items():\n",
    "    print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_iter(activation):\n",
    "    for a in activation.items():\n",
    "        yield a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp= act_iter(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for s in act_iter(activation):\n",
    "    s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = torch.Tensor(np.load(r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\activationMap\\0\\0_conv1.npy'))\n",
    "n2 = torch.Tensor(np.load(r'C:\\Users\\ms9804\\Desktop\\capstone\\5.capstoneTestVer1\\past\\0\\0_conv1.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_criterion(n1,n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation['conv1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.Tensor(torch.rand(2,64,112,112))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.append(torch.Tensor(torch.rand(1,330)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = torch.cat(val,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.append(torch.Tensor([0,0,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.cat(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in labels:\n",
    "    l = str(l.tolist())\n",
    "    print(str(l))\n",
    "    print(type(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.flatten(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.flatten(torch.Tensor([0,1,2,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(temp,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(str(label[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation['conv1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.append(activation['conv1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = torch.randint(0,100,(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = act.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in act:\n",
    "    print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_trans(aset = False):\n",
    "    if aset == False:\n",
    "        print('false')\n",
    "    if aset == True:\n",
    "        print('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_trans(aset = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
